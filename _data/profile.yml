primary_name: "Shuai Zhong (ÈçæÂ∏•)"
secondary_name: "‚Ä¢ Chris"
navbar_name: "Shuai Zhong"

positions:
- name: M.Phil. Student @ <a href="https://www.cds.hku.hk/" target="_blank">HKU-CDS</a>
- name: VLM Agent Researcher

email: "chris_zsa@connect.hku.hk"
# cv_link: link-to-your-cv-file
gscholar: lYQsYYoAAAAJ  # This is an example, replace it with your own Google Scholar ID
github: chris-zsa
twitter: chris_zsa  # Do not include the '@' symbol
# wechat_qrcode: /assets/images/etc/wechat.jpg
# wechat_prompt: >-
#   Please tell me your <strong>name</strong> and <strong>affiliation</strong> (current or past) when adding my wechat. Thanks!
# linkedin: your-linked-in-id
# orcid: 0000-0000-0000-0000

short_bio_text_justify: false
short_bio: >-
  <p>
    Hi there. I'm Shuai Zhong (ÈçæÂ∏•, / à Ç ä≈ã  Éua…™/), you can also call me Chris. I'm a M.Phil. student @ <a href="https://mmlab.hk/" target="_blank">HKU MMLab</a>, 
    <a href="https://maps.google.com/maps?q=The+University+of+Hong+Kong&t=&z=15&ie=UTF8&iwloc=&output=embed" target="_blank">The University of Hong Kong</a>.
  </p>
  <p> 
    Currently, I'm exploring the intersection of 
    Vision-Language Foundation Models and Agentic AI Systems under the supervision of 
    <a href="https://luoping.me/" target="_blank">Dr. Ping Luo</a> and co-supervision of 
    <a href="https://ikekonglp.github.io/" target="_blank">Dr. Lingpeng Kong</a>. 
    I also had the privilege of working with <a href="https://xh-liu.github.io/" target="_blank">Dr. Xihui Liu</a> 
    as my UG FYP advisor @ <a href="https://www.eee.hku.hk/" target="_blank">HKU-EEE</a>. My research focuses on developing autonomous agents that can perceive, reason, and act in complex multimodal environments - 
    particularly in GUI control and collaborative multi-agent scenarios. ü§ñ
  </p>
  <p>
    My work spans from adversarial robustness in VLMs (exploring novel jailbreaking paradigms) to emergent behaviors in 
    multi-agent reinforcement learning systems. I'm particularly interested in staged workflows for interleaved RL, 
    where we decompose end-to-end VLM agents into specialized planner-actor architectures. Recent projects include 
    developing dense reward models for GUI automation and investigating the interpretability of vision-language reasoning chains.
  </p>

portrait_url: /assets/images/photos/portrait.jpg
portrait_caption: >-
  Probably thinking about how to make AI agents more cooperative (while less likely to take over the world :P

education:
- name: The University of Hong Kong
  logo: /assets/images/badges/HKU_logo.png
  position: >- 
    M.Phil. in Computer Science <br/>
    Supervised by Dr. Ping Luo
  date: Sep. 2025 - Jul. 2027 (expected)
- name: The University of Hong Kong
  logo: /assets/images/badges/HKU_logo.png
  position: >-
    B.Eng. in Computer Engineering <br/>
  date: Sep. 2020 - Jul. 2025


experience:
- name: TCL Corporate Research (HK) Co., Ltd.
  logo: /assets/images/badges/TCL_logo.png
  position: Research Intern
  date: May 2025 - Present
- name: HKU MMLab
  logo: /assets/images/badges/HKU_logo.png
  position: Research Assistant
  date: May 2025 - Present
- name: HKU NLP Lab
  logo: /assets/images/badges/HKU_logo.png
  position: Research Assistant
  date: Sep. 2023 - Jan. 2025
- name: Hangzhou Raycloud Technology Co., Ltd.
  logo: /assets/images/badges/Raycloud_logo.png
  position: Research Intern
  date: Jul. 2022 - Aug. 2022

